{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33c96c8-66c6-4ff7-816d-cd262202f20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from threading import Thread, Event\n",
    "from queue import Queue\n",
    "import asyncio\n",
    "\n",
    "import cv2\n",
    "import opencv_jupyter_ui as jcv2\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "import driver\n",
    "from pynq.pl_server.device import Device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f81583-4117-460c-b8d5-5849bd8c561b",
   "metadata": {},
   "source": [
    "### Driver Base Modification\n",
    "\n",
    "New methods added in driver_base.py to perform async execution:\n",
    "\n",
    "```python\n",
    "def async_exec(self, input_npy)\n",
    "def polling_out_dma_ready(self)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6da744-8942-4438-8e1a-915834e1cc4d",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1220e369-a647-438f-86ce-a2d5f2a88d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAME_IN_W = 640\n",
    "FRAME_IN_H = 480\n",
    "N_FRAMES = 240\n",
    "\n",
    "IMG_W_RSZ = 224\n",
    "IMG_H_RSZ = 224\n",
    "BATCH_SIZE = 20\n",
    "FPGA_CLK = 5.0\n",
    "\n",
    "CAP_FPS = BATCH_SIZE\n",
    "\n",
    "WARM_UP_FRAMES = 5\n",
    "VERBOSE = False\n",
    "# Sleep if there are no new frames from the camera\n",
    "SLEEP_BATCH_FRAME = 0.01\n",
    "# Sleep DMA while inference is calculated: used for polling DMA\n",
    "SLEEP_DMA_POLL = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98cfa14-00c5-4d6c-80cd-00171964d9ca",
   "metadata": {},
   "source": [
    "# Accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ccb9a0-759a-4314-b5a9-208d684ef1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_device = Device.devices[0]\n",
    "\n",
    "accel = driver.FINNExampleOverlay(\n",
    "    bitfile_name = '../bitfile/finn-accel.bit', \n",
    "    platform = \"zynq-iodma\",\n",
    "    io_shape_dict = driver.io_shape_dict, \n",
    "    batch_size = BATCH_SIZE,\n",
    "    fclk_mhz = FPGA_CLK,\n",
    "    runtime_weight_dir = \"runtime_weights/\", \n",
    "    device=my_device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda7a1ea-3845-4b95-9adf-02ba2f5432bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = accel.throughput_test()\n",
    "file = open(\"nw_metrics_threads.txt\", \"w\")\n",
    "file.write(str(res))\n",
    "file.close()\n",
    "print(\"Results written to nw_metrics.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb3e3ce-c23a-48d3-b832-a5b57ccf3ebe",
   "metadata": {},
   "source": [
    "# Camera Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdb31dc-5544-4420-80d0-079b3d9da722",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_videocapture(width=1280, height=720, fps = 30):\n",
    "    camera = cv2.VideoCapture(0, cv2.CAP_V4L2)\n",
    "    camera.set(cv2.CAP_PROP_FRAME_WIDTH, width)\n",
    "    camera.set(cv2.CAP_PROP_FRAME_HEIGHT, height)\n",
    "    camera.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc('M', 'J', 'P', 'G'))\n",
    "    camera.set(cv2.CAP_PROP_FPS, fps)\n",
    "    return camera"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4b91d1-eece-4cad-abef-6d64ac42b40f",
   "metadata": {},
   "source": [
    "# Camera Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfae58d-5718-4ef1-b346-fc978918cbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frames(\n",
    "    event_warm_up_ready,\n",
    "    event_initial_plot_ready,\n",
    "    queue_warm_up,\n",
    "    queue_frames,\n",
    "    frame_in_w, \n",
    "    frame_in_h, \n",
    "    n_frames,\n",
    "    batch_size,\n",
    "    warm_up_frames = 5,\n",
    "    cap_fps = 30,\n",
    "    verbose = False):\n",
    "    \n",
    "    '''\n",
    "    Get frames continuously from the camera.\n",
    "    '''\n",
    "    \n",
    "    capture = init_videocapture(width=frame_in_w, height=frame_in_h, fps=cap_fps)\n",
    "    print(f'$ Camera Thread: Is webcam open: {capture.isOpened()}')\n",
    "    img_w = capture.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "    img_h = capture.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "    cv_fps = capture.get(cv2.CAP_PROP_FPS) \n",
    "    print(f'$ Camera Thread: Camera (width, height) = ({img_w}, {img_h}) - FPS = {cv_fps}')\n",
    "    \n",
    "    ################################\n",
    "    #           Warm Up            #\n",
    "    ################################\n",
    "    warm_up_count = 0\n",
    "    while (warm_up_count < warm_up_frames):\n",
    "        ret, frame = capture.read()\n",
    "        queue_warm_up.put(frame)\n",
    "        warm_up_count += 1\n",
    "    event_warm_up_ready.set()\n",
    "    print(f'\\n$ Camera Thread: Warm up of {warm_up_frames} frames finished\\n')\n",
    "    print(f'\\n$ Camera Thread: Waiting for Initial Plot\\n')\n",
    "    event_initial_plot_ready.wait()\n",
    "    print(f'\\n$ Camera Thread: Initial Plot finished\\n')\n",
    "    \n",
    "    ################################\n",
    "    #            Loop              #\n",
    "    ################################\n",
    "    img_count = 0\n",
    "    start = datetime.now()\n",
    "    while (img_count < n_frames):\n",
    "        ret, frame = capture.read()\n",
    "        queue_frames.put(frame)\n",
    "        if verbose == True:\n",
    "            img_in_batch = img_count % batch_size\n",
    "            print(f'$ Camera Thread: got image = {img_count} - Id in batch: {img_in_batch} - Queue frames size = {queue_frames.qsize()}.')\n",
    "        img_count += 1\n",
    "    end = datetime.now()\n",
    "    \n",
    "    queue_frames.put(None) # Signal plot_frames to stop\n",
    "    \n",
    "    delta_secs = (end-start).total_seconds()\n",
    "    fps = round(n_frames / delta_secs, 1)\n",
    "    print(\"\\n$ *******************************\")\n",
    "    print(f'$ Camera Thread: FPS = {fps:.1f}')\n",
    "    print(\"$ *******************************\\n\")\n",
    "    \n",
    "    capture.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cae2b5-c646-4c16-a8f6-4e91882d4637",
   "metadata": {},
   "source": [
    "# Batches Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8f7985-cd97-48ec-a408-134358a097c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_batches(\n",
    "    queue_frames, \n",
    "    queue_batches, \n",
    "    event_batch_ready, \n",
    "    batch_size,\n",
    "    queue_frames_2_plot,\n",
    "    sleep_time = 0.02,\n",
    "    verbose = False): #, queue_frames_2_plot):\n",
    "    \n",
    "    '''\n",
    "    Do batches taking images from Queue Frames. Sleep if there are no frames in the queue.\n",
    "        - BGR2RGB\n",
    "        - Resize\n",
    "        - Expand dims to add batch dim\n",
    "    Once a batch is formed, put it in Queue Batches.\n",
    "    Queue Batches is of size 1, to block if previous batch was not predicted by the accelerator.\n",
    "    \n",
    "    Put the first frame of the batch in the Queue Frames to Plot, to plot it afterwards.\n",
    "    '''\n",
    "    \n",
    "    img_id = 0\n",
    "    batch_idx = 0\n",
    "    \n",
    "    while True:\n",
    "        if queue_frames.empty():\n",
    "            if verbose == True:\n",
    "                print(\">> Batches Thread: empty queue frames from camera\")\n",
    "            time.sleep(sleep_time)\n",
    "        else:\n",
    "            frame = queue_frames.get()\n",
    "            if verbose == True:\n",
    "                print(f\">> Batches Thread: image {img_id} for batch {batch_idx} - Queue batches size = {queue_batches.qsize()}.\")\n",
    "            if frame is None:\n",
    "                break \n",
    "            # Form batches for accel prediction\n",
    "            img = frame.copy()\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = cv2.resize(img, (IMG_W_RSZ, IMG_H_RSZ), interpolation = cv2.INTER_LINEAR)\n",
    "            assert img.dtype == \"uint8\", \"Image datatype must be UINT8\"\n",
    "            img = np.expand_dims(img, axis=0)\n",
    "            if img_id == 0:\n",
    "                # To plot images inside notebook\n",
    "                queue_frames_2_plot.put([batch_idx, frame])\n",
    "                if verbose == True:\n",
    "                    print(f\">> Batches Thread: plot frame added to batch {batch_idx} - Queue plot size = {queue_frames_2_plot.qsize()}.\")\n",
    "                batch_imgs = img\n",
    "            else:\n",
    "                batch_imgs = np.concatenate((batch_imgs, img), axis=0)\n",
    "            if img_id == (batch_size - 1):\n",
    "                # Put blocks if accel did not get previous batch\n",
    "                queue_batches.put([batch_idx, batch_imgs])\n",
    "                if verbose == True:\n",
    "                    print(f\">> Batches Thread: Batch {batch_idx} for accel - Queue batches size = {queue_batches.qsize()}.\")\n",
    "                event_batch_ready.set()\n",
    "                batch_idx += 1\n",
    "            img_id = (img_id + 1) % batch_size\n",
    "            queue_frames.task_done()\n",
    "    \n",
    "    # Signal queues to stop\n",
    "    print(\">> Batches Thread: No more batches to do. Put None.\")\n",
    "    queue_batches.put([batch_idx, None])\n",
    "    queue_frames_2_plot.put([batch_idx, None])\n",
    "    time.sleep(5)\n",
    "    event_batch_ready.set()\n",
    "    #queue_frames_2_plot.put(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610b4853-22f9-4cf0-84b3-c65dc48dcdf6",
   "metadata": {},
   "source": [
    "# Accel Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6d086e-1d66-4230-8070-df1947290f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accel_exec(\n",
    "    queue_batches, \n",
    "    event_batch_ready, \n",
    "    event_accel_exec, \n",
    "    event_yhat_ready_accel,\n",
    "    verbose = False):\n",
    "    \n",
    "    batch_idx = 0\n",
    "    \n",
    "    while True:\n",
    "        event_batch_ready.wait()\n",
    "        event_batch_ready.clear()\n",
    "        # It avoids getting the new batch if previous one was not retrieved from DMA first\n",
    "        # Therefore, this thread blocks until previous inference is performed\n",
    "        # It causes that do_batches and get_frames gets blocked too\n",
    "        event_yhat_ready_accel.wait()\n",
    "        event_yhat_ready_accel.clear()\n",
    "        do_batch_idx, batch = queue_batches.get()\n",
    "        assert do_batch_idx == batch_idx, f\"@ Accel Thread: do batch idx {do_batch_idx} does not match accel batch idx {batch_idx}.\"\n",
    "        if batch is None:\n",
    "            print(\"@@@ Accel Thread: No more Batches signal received.\")\n",
    "            break\n",
    "        if verbose == True:\n",
    "            print(f'@@@ Accel Thread: Batch idx {batch_idx}. Batch shape = {batch.shape}.')\n",
    "        # Execute accelerator\n",
    "        if verbose == True:\n",
    "            start_accel = datetime.now()\n",
    "        accel.async_exec([batch])\n",
    "        # Notify DMA Poll that it can start polling for prediction ready\n",
    "        if verbose == True:\n",
    "            end_accel = datetime.now()\n",
    "            print(f'@@@ Accel Thread: time to exec accel {(end_accel-start_accel).microseconds/1e3:.2f} [ms] - {end_accel}')   \n",
    "        event_accel_exec.set()\n",
    "        batch_idx += 1  \n",
    "        queue_batches.task_done()\n",
    "        \n",
    "    queue_batches.task_done()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93997fc1-87d7-4821-b713-5ff8bcdddc45",
   "metadata": {},
   "source": [
    "# Check DMA Result Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b1bad2-fbfe-4b2d-a488-a9f316fecb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dma_ready(\n",
    "    event_accel_exec, \n",
    "    queue_yhat, \n",
    "    event_yhat_ready,\n",
    "    event_yhat_ready_accel,\n",
    "    n_frames, \n",
    "    batch_size,\n",
    "    sleep_time = 0.01,\n",
    "    verbose = False):\n",
    "    \n",
    "    '''\n",
    "    Polls the DMA to check if prediction was already completed by the accelerator.\n",
    "    It signals the accelerator that prediction was completed, so it can load next batch: event_yhat_ready_accel.\n",
    "    It signals the main thread that prediction is ready, so it can plot it: event_yhat_ready. \n",
    "    \n",
    "    With this strategy, it blocks do_batches, as the accelerator cannot accept new batches until previous one is completed.\n",
    "    '''\n",
    "    \n",
    "    total_batches = int(n_frames / batch_size)\n",
    "    batch_idx = 0\n",
    "    \n",
    "    accel_preds_times = []\n",
    "    \n",
    "    while (batch_idx < total_batches):\n",
    "        event_accel_exec.wait()\n",
    "        start_accel = datetime.now()           \n",
    "        event_accel_exec.clear()\n",
    "        if verbose == True:\n",
    "            print(f\"**** DMA Thread: Accel started Execution - {start_accel}.\")\n",
    "        while True:\n",
    "            if verbose == True:\n",
    "                now_time = datetime.now()   \n",
    "                print(f\"**** DMA Thread: ... Polling for DMA result ... : {now_time}\")\n",
    "            out_ready, yhat = accel.polling_out_dma_ready()\n",
    "            if out_ready == True:\n",
    "                queue_yhat.put([batch_idx, yhat])\n",
    "                \n",
    "                if verbose == True:\n",
    "                    print(\"\\nOutput DMA ready\")\n",
    "                    print(f'{yhat}')\n",
    "                    # Calculate time between predictions\n",
    "                    end_accel = datetime.now()\n",
    "                    if batch_idx == 0:\n",
    "                        accel_preds_times.append(end_accel)\n",
    "                    else:\n",
    "                        accel_preds_times.append(end_accel)\n",
    "                        time_between_preds = accel_preds_times[1] - accel_preds_times[0]\n",
    "                        if batch_idx == 1:\n",
    "                            accel_preds_sum = time_between_preds\n",
    "                        else:\n",
    "                            accel_preds_sum = accel_preds_sum + time_between_preds\n",
    "                        accel_preds_mean_time = accel_preds_sum / batch_idx\n",
    "                        accel_preds_times.pop(0)\n",
    "                        print(f'\\n_____ Accel between predictions: {time_between_preds.total_seconds():.2f} [secs] _____')\n",
    "                        print(f'_____ Mean Accel between predictions: {accel_preds_mean_time.total_seconds():.2f} [secs] _____')\n",
    "                    print(f'_____ Accel elapsed time: {(end_accel-start_accel).microseconds/1e3:.2f} [ms] _____\\n')   \n",
    "                \n",
    "                # Print time between predictions and accel elapsed time close to plot window\n",
    "                else:\n",
    "                    end_accel = datetime.now()\n",
    "                    if batch_idx == 0:\n",
    "                        accel_preds_times.append(end_accel)\n",
    "                        str_2_print = \"\"\n",
    "                    else:\n",
    "                        accel_preds_times.append(end_accel)\n",
    "                        time_between_preds = accel_preds_times[1] - accel_preds_times[0]\n",
    "                        if batch_idx == 1:\n",
    "                            accel_preds_sum = time_between_preds\n",
    "                        else:\n",
    "                            accel_preds_sum = accel_preds_sum + time_between_preds\n",
    "                        accel_preds_mean_time = accel_preds_sum / batch_idx\n",
    "                        accel_preds_times.pop(0)\n",
    "                        str_2_print = f'\\nBatch idx = {batch_idx}\\n'\n",
    "                        str_2_print += f'--- Accel between predictions: {time_between_preds.total_seconds():.2f} [secs]\\n'\n",
    "                        str_2_print += f'*** Mean Accel between predictions: {accel_preds_mean_time.total_seconds():.2f} [secs]\\n'\n",
    "                    str_2_print += f'... Accel elapsed time: {(end_accel-start_accel).microseconds/1e3:.2f} [ms]\\n'\n",
    "                    print(str_2_print, end='\\r')\n",
    "                \n",
    "                event_yhat_ready.set()\n",
    "                # Finish blocking of accel if needed\n",
    "                event_yhat_ready_accel.set()\n",
    "                batch_idx += 1\n",
    "                break\n",
    "            else:\n",
    "                if verbose == True:\n",
    "                    print(f\"**** DMA Thread: yhat not ready. Sleep {sleep_time} [secs].\")\n",
    "                time.sleep(sleep_time)\n",
    "            \n",
    "    # Signal queues to stop\n",
    "    print(\"**** DMA Thread: No more batches to do. Put None.\")\n",
    "    queue_yhat.put([batch_idx, None])\n",
    "    time.sleep(5)\n",
    "    event_yhat_ready.set() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b8b61b-48a4-4768-8575-d8694999278a",
   "metadata": {},
   "source": [
    "# Plot Thread"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d24712-a899-45b4-879f-3dec9fcfb0eb",
   "metadata": {},
   "source": [
    "#### Colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f52aae-b713-4bcc-9ad6-2771fad63b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "BLACK_COLOR = (0, 0, 0)\n",
    "WHITE_COLOR = (255, 255, 255)\n",
    "GRAY_COLOR = (50, 50, 50)\n",
    "RED_COLOR = (0,0,255)\n",
    "BLUE_COLOR = (255,255,0) # CYAN\n",
    "GREEN_COLOR = (0,255,0)\n",
    "YELLOW_COLOR = (0,255,255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e2fab5-0d8e-4cf1-8cd8-9fe20454d49b",
   "metadata": {},
   "source": [
    "#### Draw Prediction in Frame Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b33e3b-2c16-4388-8b4f-e03bbfd55730",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_pred_box(yhat, img_to_plot, img_w, img_h):\n",
    "\n",
    "    yhat_str = np.array2string(yhat)\n",
    "    empty_str = \"Empty: \" + yhat_str\n",
    "    smoke_str = \"Smoke: \" + yhat_str\n",
    "    fire_str = \"Fire: \" + yhat_str\n",
    "    smoke_fire_str = \"Smoke & Fire: \" + yhat_str\n",
    "\n",
    "    # Empty\n",
    "    if yhat[0] < 0.5 and yhat[1] < 0.5:\n",
    "        cv2.rectangle(img_to_plot, (0,0), (img_w, img_h), GRAY_COLOR, 20)\n",
    "        cv2.rectangle(img_to_plot, (0,0), (250, 35), GRAY_COLOR, -1)\n",
    "        cv2.putText(img_to_plot, empty_str, (8, 25), cv2.FONT_HERSHEY_SIMPLEX, 1, WHITE_COLOR, 1) \n",
    "    # Smoke\n",
    "    elif yhat[0] > 0.5 and yhat[1] < 0.5:\n",
    "        cv2.rectangle(img_to_plot, (0,0), (img_w, img_h), BLUE_COLOR, 20)\n",
    "        cv2.rectangle(img_to_plot, (0,0), (270, 35), BLUE_COLOR, -1)\n",
    "        cv2.putText(img_to_plot, smoke_str, (8, 25), cv2.FONT_HERSHEY_SIMPLEX, 1, BLACK_COLOR, 1) \n",
    "    # Fire\n",
    "    elif yhat[0] < 0.5 and yhat[1] > 0.5:\n",
    "        cv2.rectangle(img_to_plot, (0,0), (img_w, img_h), RED_COLOR, 20)\n",
    "        cv2.rectangle(img_to_plot, (0,0), (210, 35), RED_COLOR, -1)\n",
    "        cv2.putText(img_to_plot, fire_str, (8, 25), cv2.FONT_HERSHEY_SIMPLEX, 1, BLACK_COLOR, 1) \n",
    "    # Smoke & Fire\n",
    "    elif yhat[0] > 0.5 and yhat[1] > 0.5:\n",
    "        cv2.rectangle(img_to_plot, (0,0), (img_w, img_h), YELLOW_COLOR, 20)\n",
    "        cv2.rectangle(img_to_plot, (0,0), (500, 35), YELLOW_COLOR, -1)\n",
    "        cv2.putText(img_to_plot, smoke_fire_str, (8, 25), cv2.FONT_HERSHEY_SIMPLEX, 1, BLACK_COLOR, 1)\n",
    "        \n",
    "    return img_to_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba46855a-774a-42b6-b924-76fc51090b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def plot_frames(\n",
    "    event_warm_up_ready,\n",
    "    event_initial_plot_ready,\n",
    "    queue_warm_up,\n",
    "    event_yhat_ready,\n",
    "    queue_yhat,\n",
    "    queue_frames_2_plot):\n",
    "\n",
    "    ################################\n",
    "    #           Warm Up            #\n",
    "    ################################\n",
    "    event_warm_up_ready.wait()\n",
    "    print(':):):) Plot Thread: start Initial Plot.')    \n",
    "    for _ in range(queue_warm_up.qsize()):\n",
    "        new_frame = queue_warm_up.get()\n",
    "        jcv2.imshow('UAV', new_frame)\n",
    "        queue_warm_up.task_done()\n",
    "    event_initial_plot_ready.set()\n",
    "    \n",
    "    ################################\n",
    "    #            Loop              #\n",
    "    ################################\n",
    "    plot_batch_idx = 0\n",
    "\n",
    "    while True:\n",
    "        event_yhat_ready.wait()\n",
    "        event_yhat_ready.clear()\n",
    "        yhat_batch_idx, yhat = queue_yhat.get()\n",
    "        plot_frames_idx, frame_to_plot = queue_frames_2_plot.get()\n",
    "        assert yhat_batch_idx == plot_batch_idx, f':) Plot Thread: plot batch idx {plot_batch_idx} does not match yhat batch idx {yhat_batch_idx}.'\n",
    "        assert plot_frames_idx == plot_batch_idx, f':) Plot Thread: plot frames idx {plot_frames_idx} does not match batch idx {yhat_batch_idx}.'\n",
    "        if yhat is None:\n",
    "            print(':):):) Plot Thread: yhat is None received -> Execution Finished')\n",
    "            break\n",
    "        else:\n",
    "            yhat_mean = np.mean(yhat, axis=0)\n",
    "            smoke_mean = yhat_mean[0]\n",
    "            fire_mean = yhat_mean[1]\n",
    "            if VERBOSE:\n",
    "                print(f':):):) Plot Thread: yhat\\n {yhat}')\n",
    "                print(f':):):) Plot Thread: smoke mean = {smoke_mean}')\n",
    "                print(f':):):) Plot Thread: fire mean = {fire_mean}')\n",
    "            frame_to_plot = draw_pred_box(yhat_mean, frame_to_plot, FRAME_IN_W, FRAME_IN_H)   \n",
    "            jcv2.imshow('UAV', frame_to_plot)\n",
    "            if jcv2.waitKey(1)==ord('q'):\n",
    "                break \n",
    "            plot_batch_idx += 1\n",
    "            queue_yhat.task_done()\n",
    "            queue_frames_2_plot.task_done()\n",
    "\n",
    "    queue_yhat.task_done()\n",
    "    queue_frames_2_plot.task_done()\n",
    "    jcv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f59e005-42ba-4e3a-8f49-4b9ee95a6901",
   "metadata": {},
   "source": [
    "# Threads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0961f6f1-8cad-470b-a3a1-b5aac429492a",
   "metadata": {},
   "source": [
    "### Setup Queues\n",
    "\n",
    "Accel cannot start if previous prediction was not completed. Therefore, it cannot get a new batch.\n",
    "Setting the Queue of Batches to 1 blocks do_batches if previous prediction was not completed.\n",
    "\n",
    "There is a balance between this blocking and Queue Frames size, which could grow to the maximum and block/slow down the camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c52bd50-acbb-4044-8cac-2717bc5bbc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "queue_warm_up = Queue(maxsize=WARM_UP_FRAMES)\n",
    "\n",
    "queue_frames = Queue(maxsize=BATCH_SIZE*2) # -> BATCH_SIZE*2 is very conservative, it should be reduced\n",
    "queue_batches = Queue(maxsize=1)\n",
    "queue_yhat = Queue(maxsize=1)\n",
    "queue_frames_2_plot = Queue(maxsize=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4655934-b530-4a27-87e2-4c290fb2466e",
   "metadata": {},
   "source": [
    "### Setup Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26bf096-87e6-4841-b31a-363bfbf4c7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_warm_up_ready = Event()\n",
    "event_initial_plot_ready = Event()\n",
    "\n",
    "event_batch_ready = Event()\n",
    "event_accel_exec = Event()\n",
    "event_yhat_ready_accel = Event()\n",
    "event_yhat_ready_accel.set() # To let first batch start in the accelerator\n",
    "event_yhat_ready = Event()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf89f72-db10-4da2-8565-2ccc5812bcc5",
   "metadata": {},
   "source": [
    "### Setup Threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ae5cd3-a91e-4d7c-b86c-fffabd208590",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_thread = Thread(\n",
    "    target=get_frames, \n",
    "    args=(\n",
    "        event_warm_up_ready, event_initial_plot_ready, queue_warm_up,\n",
    "        queue_frames, FRAME_IN_W, FRAME_IN_H, N_FRAMES, BATCH_SIZE, WARM_UP_FRAMES, CAP_FPS, VERBOSE,))\n",
    "\n",
    "batches_thread = Thread(\n",
    "    target=do_batches, \n",
    "    args=(queue_frames, queue_batches, event_batch_ready, BATCH_SIZE, queue_frames_2_plot, SLEEP_BATCH_FRAME, VERBOSE,))\n",
    "\n",
    "accel_thread = Thread(\n",
    "    target=accel_exec, \n",
    "    args=(queue_batches, event_batch_ready, event_accel_exec, event_yhat_ready_accel, VERBOSE,))\n",
    "\n",
    "check_dma_ready = Thread(\n",
    "    target=check_dma_ready, \n",
    "    args=(event_accel_exec, queue_yhat, event_yhat_ready, event_yhat_ready_accel, N_FRAMES, BATCH_SIZE, SLEEP_DMA_POLL, VERBOSE,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85c99bb-707e-4e16-9154-8216101be095",
   "metadata": {},
   "source": [
    "### Asyncio Thread to Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036787d8-d358-4235-ba3b-db95812bc810",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_event_loop(loop):\n",
    "    # report a message\n",
    "    print('Asyncio event loop is running')\n",
    "    # set the loop for the current thread\n",
    "    asyncio.set_event_loop(loop)\n",
    "    # run the event loop until stopped\n",
    "    loop.run_forever()\n",
    "    \n",
    "# create a new event loop (low-level api)\n",
    "loop = asyncio.new_event_loop()\n",
    "\n",
    "plot_thread = Thread(target=run_event_loop, args=(loop,), daemon=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a9135c-6258-4ca1-afe4-cc644685b8f5",
   "metadata": {},
   "source": [
    "### Start Threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4064e485-d18a-4f16-a7cc-fbe6e6e07564",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_running = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501848ab-6c81-4dab-ab79-46ef5c17cea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_thread.start()\n",
    "batches_thread.start()\n",
    "accel_thread.start()\n",
    "check_dma_ready.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21938f1-b1f4-4e5c-8453-cd0b8ba62fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_thread.start()\n",
    "print(\"\\nWaiting for capture thread\")\n",
    "\n",
    "future = asyncio.run_coroutine_threadsafe(plot_frames(\n",
    "                                                event_warm_up_ready, event_initial_plot_ready, queue_warm_up,\n",
    "                                                event_yhat_ready,\n",
    "                                                queue_yhat,\n",
    "                                                queue_frames_2_plot), \n",
    "                                            loop)\n",
    "# wait for the task to finish\n",
    "value = future.result()\n",
    "# report a message\n",
    "print(f'Got Async Result: {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debfe408-12bf-47c4-8642-97ca585c611e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Wait for Threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a5734e-534e-4498-8a29-d59e0ba45bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap_thread.join()\n",
    "# batches_thread.join()\n",
    "# accel_thread.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05526cf4-7d3a-4804-a1a2-78ce69d367a7",
   "metadata": {},
   "source": [
    "# Main Thread Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd930c5c-56ff-4d71-a68c-fad9dc17cd88",
   "metadata": {},
   "source": [
    "### Plot inside Asyncio Loop Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862dbcef-4d19-43ec-b276-a42edb39cf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_thread.join()\n",
    "    \n",
    "end_running = datetime.now()\n",
    "\n",
    "print(f'\\nElapsed time = {end_running - start_running}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5420a923-2c1b-4155-b285-84ac8838469d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Plot in Main Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488bb88c-a187-4855-9bd2-2003809ab8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# When yhat is ready, it retrives a frame from Queue Frames to Plot and yhat from Queue Yhat.\n",
    "# Calculates the mean of yhat for both classes and plot it.\n",
    "# '''\n",
    "\n",
    "# plot_batch_idx = 0\n",
    "\n",
    "# while True:\n",
    "#     event_yhat_ready.wait()\n",
    "#     event_yhat_ready.clear()\n",
    "#     yhat_batch_idx, yhat = queue_yhat.get()\n",
    "#     plot_frames_idx, frame_to_plot = queue_frames_2_plot.get()\n",
    "#     assert yhat_batch_idx == plot_batch_idx, f':) Main Thread: plot batch idx {plot_batch_idx} does not match yhat batch idx {yhat_batch_idx}.'\n",
    "#     assert plot_frames_idx == plot_batch_idx, f':) Main Thread: plot frames idx {plot_frames_idx} does not match batch idx {yhat_batch_idx}.'\n",
    "#     if yhat is None:\n",
    "#         print(':):):) Main Thread: yhat is None received -> Execution Finished')\n",
    "#         break\n",
    "#     else:\n",
    "#         smoke_mean = np.mean(yhat[:, 0])\n",
    "#         fire_mean = np.mean(yhat[:, 1])\n",
    "#         if VERBOSE:\n",
    "#             print(f':):):) Main Thread: yhat\\n {yhat}')\n",
    "#             print(f':):):) Main Thread: smoke mean = {smoke_mean}')\n",
    "#             print(f':):):) Main Thread: fire mean = {fire_mean}')\n",
    "#             # print(f':):):) Main Thread: yhat\\n {type(yhat)}')\n",
    "#             # print(f':):):) Main Thread: yhat\\n {yhat.shape}')\n",
    "#         jcv2.imshow('UAV', frame_to_plot)\n",
    "#         if jcv2.waitKey(1)==ord('q'):\n",
    "#             break \n",
    "#         plot_batch_idx += 1\n",
    "#         queue_yhat.task_done()\n",
    "#         queue_frames_2_plot.task_done()\n",
    "        \n",
    "# queue_yhat.task_done()\n",
    "# queue_frames_2_plot.task_done()\n",
    "# jcv2.destroyAllWindows()\n",
    "\n",
    "# end_running = datetime.now()\n",
    "\n",
    "# print(f'\\nElapsed time = {end_running - start_running}.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
